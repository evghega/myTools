{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF IDF\n",
    "\n",
    "\"normalization\" & :\n",
    " # Code\n",
    "    Sum=Sum+(x[pointer]*y[pointer])\n",
    "    result = result +(val*val)\n",
    "        return math.sqrt(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector space model\n",
    "\n",
    "Gives option to put difrent data type on same dementional model \n",
    "\n",
    "* nice option but is where more options to do same work ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "#matrix from home work 2\n",
    "class matrix:\n",
    "    def __init__(self,df,id_len=100):\n",
    "        \n",
    "        self.df=df.fillna(\"\")\n",
    "        self.id_len=id_len \n",
    "        split_test1=(self.df[\"tweet\"][:id_len]).values\n",
    "        self.wordList=set((' '.join(list((np.array_split(split_test1,1))[0]))).split())\n",
    "       \n",
    "  \n",
    "        # Convert the dictionary into DataFrame \n",
    "        self.new_df = pd.DataFrame( [[bool(False)]*len(self.wordList)]*self.id_len )\n",
    "        self.new_df.columns = self.wordList\n",
    "        \n",
    "        \n",
    "        ID=0\n",
    "        for tweet in self.df[\"tweet\"][:id_len]:\n",
    "            tokens = tweet.split()\n",
    "            for token in tokens:\n",
    "                if token in self.wordList:\n",
    "                    self.new_df[token][ID]=bool(True)\n",
    "            ID += 1\n",
    "            \n",
    "        \n",
    "        #2.1.1\n",
    "        print(\"\")\n",
    "        print(\"#2.1.1\")\n",
    "        self.new_df.to_csv('out_matrix.csv', index=False)\n",
    "        print(\"file out.csv saved \")\n",
    "        self.new_df.T.to_csv('out_matrix_T.csv', index=False)\n",
    "        print(\"file out_T.csv saved \")\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        #2.1.2\n",
    "        print(\"\")\n",
    "        print(\"#2.1.2\")\n",
    "        print(\"File size : \",os.path.getsize('out_matrix.csv'),\"Byte\")\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        #2.1.3\n",
    "        print(\"\")\n",
    "        print(\"#2.1.3\")\n",
    "        \n",
    "        #print(self.new_df.value_counts())\n",
    "        #for word in self.new_df:\n",
    "            #print(self.new_df[word].value_counts())      \n",
    "                \n",
    "        print(\"\")\n",
    "        print(\"\")\n",
    "        print(self.new_df.head())\n",
    "                        \n",
    "    \n",
    "    def And(self, words_list=[]):\n",
    "        \"\"\"\n",
    "        works like set operator \"intersection\"\n",
    "        \n",
    "        :param words_list: list of words to find\n",
    "        :return: appearences of words_list sorted by intersection-operrator\n",
    "        \"\"\"\n",
    "        set_dict={}\n",
    "        for word in words_list:\n",
    "            if word not in self.new_df:\n",
    "                return \"No match\"\n",
    "\n",
    "            tempData=(self.new_df[word].loc[self.new_df[word]==True]).index\n",
    "\n",
    "            set_dict[word]=set(tempData.values)\n",
    "\n",
    "        result=None\n",
    "        \n",
    "        for word in set_dict:\n",
    "            if result == None:\n",
    "                result = set_dict[word]\n",
    "\n",
    "            else:\n",
    "                result = (set(result)).intersection(set(set_dict[word]))\n",
    "                \n",
    "  \n",
    "            new_result=[]\n",
    "    \n",
    "            for index in result:\n",
    "                new_result.append(index + 1)\n",
    "       \n",
    "        return new_result\n",
    "       \n",
    "    def Or(self, words_list):\n",
    "        \"\"\"\n",
    "        works like set operator \"union\"\n",
    "        \n",
    "        :param words_list: list of words to find\n",
    "        :return: appearences of words_list sorted by union-operrator\n",
    "        \"\"\"\n",
    "        set_dict={}\n",
    "        for word in words_list:\n",
    "            if word not in self.new_df:\n",
    "                set_dict[word]=[]\n",
    "                #return \"No match\"\n",
    "            else:\n",
    "                tempData=(self.new_df[word].loc[self.new_df[word]==True]).index\n",
    "            \n",
    "                set_dict[word]=set(tempData.values)\n",
    "            \n",
    "            #set_dict[word]=[set(self.new_df[word])]\n",
    "        \n",
    "        \n",
    "        result=None\n",
    "        \n",
    "        for word in set_dict:\n",
    "            if result == None:\n",
    "                result = set_dict[word]\n",
    " \n",
    "            else:\n",
    "                result = (set(result)).union(set(set_dict[word]))\n",
    "                    \n",
    "            new_result=[]\n",
    "            for index in result:\n",
    "                new_result.append(index + 1)\n",
    "        \n",
    "        return new_result\n",
    "        \n",
    "    def Not(self, words_list):\n",
    "        \"\"\"\n",
    "        works like set operator \"difference\"\n",
    "        \n",
    "        :param words_list: list of words to find\n",
    "        :return: appearences of words_list sorted by difference-operrator\n",
    "        \"\"\"\n",
    "        set_dict={}\n",
    "        for word in words_list:\n",
    "            if word not in self.new_df:\n",
    "                return \"No match\"\n",
    "            tempData=(self.new_df[word].loc[self.new_df[word]==True]).index\n",
    "            \n",
    "            set_dict[word]=set(tempData.values)\n",
    "            \n",
    "        result=None\n",
    "        \n",
    "        for word in set_dict:\n",
    "            if result == None:\n",
    "                result = set_dict[word]\n",
    " \n",
    "            else:\n",
    "                result = (set(result)).difference(set(set_dict[word]))\n",
    "            \n",
    "            new_result=[]\n",
    "            \n",
    "            for index in result:\n",
    "                new_result.append(index + 1)\n",
    "                \n",
    "        return new_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#2.1.1\n",
      "file out.csv saved \n",
      "file out_T.csv saved \n",
      "\n",
      "#2.1.2\n",
      "File size :  15650306 Byte\n",
      "\n",
      "#2.1.3\n",
      "\n",
      "\n",
      "   history  roommates  crush  collar  dreams  current  critiquing    cup  \\\n",
      "0    False      False  False   False   False    False       False  False   \n",
      "1    False      False  False   False   False    False       False  False   \n",
      "2    False      False  False   False   False    False       False  False   \n",
      "3    False      False  False   False   False    False       False  False   \n",
      "4    False      False  False   False   False    False       False  False   \n",
      "\n",
      "    data  strong  ...  gonna  areas  funding  berlin   cube  trusted  cabaret  \\\n",
      "0  False   False  ...  False  False    False   False  False    False    False   \n",
      "1  False   False  ...  False  False    False   False  False    False    False   \n",
      "2  False   False  ...  False  False    False   False  False    False    False   \n",
      "3  False   False  ...  False  False    False   False  False    False    False   \n",
      "4  False   False  ...  False  False    False   False  False    False    False   \n",
      "\n",
      "   gymmorgon    wah  downtown  \n",
      "0      False  False     False  \n",
      "1      False  False     False  \n",
      "2      False  False     False  \n",
      "3      False  False     False  \n",
      "4      False  False     False  \n",
      "\n",
      "[5 rows x 2606 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ttw2_finalSpell.csv')\n",
    "\n",
    "M1=matrix(df,id_len=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words\n",
    "class BOW:\n",
    "    #3.1\n",
    "    def __init__(self,df,id_len=1000):\n",
    "        self.df=df.fillna(\"\")\n",
    "        split_test=(self.df[\"tweet\"][:id_len]).values\n",
    "        \n",
    "        #new_word_list=set((' '.join(list((np.array_split(split_test,1))[0]))).split())\n",
    "\n",
    "        #print(len(new_word_list))\n",
    "        self.temp_df = pd.read_csv('out_matrix.csv')\n",
    "        \n",
    "        #############\n",
    "        split_test1=(self.df[\"tweet\"]).values\n",
    "        print(\"non set dict  =  \",len((' '.join(list((np.array_split(split_test1,1))[0]))).split()))\n",
    "        print(\" set dict  =  \",len(set((' '.join(list((np.array_split(split_test1,1))[0]))).split())))\n",
    "        \n",
    "        #############\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        self.wordList=set((' '.join(list((np.array_split(split_test,1))[0]))).split())\n",
    "        \n",
    "        \n",
    "        #print(self.wordList)\n",
    "        #print(\"self.wordList : \",self.wordList)\n",
    "        self.id_len=id_len        \n",
    "        self.new_df=None\n",
    "        \n",
    "        self.create_csv()\n",
    "        self.count_vector_create()\n",
    "        self.save_csv()\n",
    "        \n",
    "        self.create_cisine_sim_matrix()\n",
    "        \n",
    "        \n",
    "        print(\"BOW init\")\n",
    "        \n",
    "    #3.1\n",
    "    def count_vector_create(self):\n",
    "\n",
    "        for word in self.wordList:\n",
    "\n",
    "            if word in self.temp_df:\n",
    "                tempData=(self.temp_df[word].loc[self.temp_df[word]==True]).index\n",
    "\n",
    "            for ID in tempData:\n",
    "\n",
    "                    \n",
    "                freq=pd.Series(''.join(self.df['tweet'][ID]).split()).value_counts()\n",
    "\n",
    "                if word in self.temp_df:\n",
    "                    self.new_df[word][ID]=freq[word]\n",
    "\n",
    "            \n",
    "    #3.2+\n",
    "    \n",
    "    \n",
    "    # Convert the dictionary into DataFrame \n",
    "    def create_csv(self):\n",
    "        if self.wordList != None:\n",
    "            self.new_df = pd.DataFrame( [[int(0)]*len(self.wordList)]*self.id_len )\n",
    "            self.new_df.columns = self.wordList\n",
    "            print(\"create_csv\")\n",
    "    \n",
    "    def save_csv(self):\n",
    "        #if self.new_df != None and self.wordList != None:\n",
    "        self.new_df.to_csv('out_work_3.csv', index=False)\n",
    "        print(\"save_csv\")\n",
    "      \n",
    "    \n",
    "    \n",
    "    #create matrix N x N where each value of an represents doc and matrix[doc1][doc2] represents cisine_sim of 2 doc\n",
    "    def create_cisine_sim_matrix(self):\n",
    "        self.cisine_sim_matrix=pd.DataFrame( [[float(0)]*self.id_len]*self.id_len )\n",
    "        for X in range(self.id_len):\n",
    "            x = self.new_df.iloc[X].values\n",
    "            for Y in range(X,self.id_len):\n",
    "                y = self.new_df.iloc[Y].values\n",
    "\n",
    "                self.cisine_sim_matrix[Y][X]=self.cisine_sim_matrix[X][Y]=self.cisine_sim(x,y)       \n",
    "        print(self.cisine_sim_matrix)\n",
    "        \n",
    "        \n",
    "    \n",
    "    #Function for cisine_sim\n",
    "    def calc_top(self,x=None,y=None):\n",
    "        Sum=0\n",
    "        for pointer in range(len(x)):\n",
    "            Sum=Sum+(x[pointer]*y[pointer])\n",
    "        return Sum\n",
    "    \n",
    "    #Function for cisine_sim\n",
    "    def calc_gip(self,vec):\n",
    "        result=0\n",
    "        for val in vec:\n",
    "            result = result +(val*val)\n",
    "        return math.sqrt(result)\n",
    "    \n",
    "    #calc cisine_sim\n",
    "    def cisine_sim(self,x,y):    \n",
    "        top=self.calc_top(x,y)\n",
    "        bot=self.calc_gip(x) * self.calc_gip(y)\n",
    "        return (top/bot)\n",
    "        \n",
    "    #create vector for question\n",
    "    def create_qws(self,words_list=[]):\n",
    "        self.qws_df = pd.DataFrame( [[int(0)]*len(self.wordList)]*1 )\n",
    "        self.qws_df.columns = self.new_df.columns\n",
    "        for word in words_list:\n",
    "            if word in self.qws_df.columns:\n",
    "                self.qws_df[word][0] = self.qws_df[word][0] + 1\n",
    "        return self.qws_df.iloc[0].values       \n",
    "        \n",
    "        \n",
    "    #function to get all doc's sorted by cisine_sim() witch relativ to question\n",
    "    def find(self,words_list=[]):\n",
    "        result_arr=[]\n",
    "        \n",
    "        y=self.create_qws(words_list)\n",
    "        for X in range(self.id_len):\n",
    "            x = self.new_df.iloc[X].values\n",
    "            result_arr.append([self.cisine_sim(x,y),X])\n",
    "            print(\"_____________________________________________________________\")\n",
    "            print(\"_____________________________________________________________\")\n",
    "            print(\" x        =====>  \",x )\n",
    "            print(\" self.cisine_sim(x,y)        =====>  \",self.cisine_sim(x,y) )\n",
    "            print(\" result_arr        =====>  \",result_arr )\n",
    "            print(\" X        =====>  \",X )\n",
    "            print(\"_____________________________________________________________\")\n",
    "            print(\"_____________________________________________________________\")\n",
    "        return result_arr.sort(reverse=False) \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non set dict  =   196788\n",
      " set dict  =   19080\n",
      "create_csv\n",
      "save_csv\n",
      "          0         1    2    3    4    5         6         7         8    \\\n",
      "0    1.000000  0.202031  0.0  0.0  0.0  0.0  0.369406  0.000000  0.000000   \n",
      "1    0.202031  1.000000  0.0  0.0  0.0  0.0  0.522419  0.089087  0.000000   \n",
      "2    0.000000  0.000000  1.0  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
      "3    0.000000  0.000000  0.0  1.0  0.0  0.0  0.000000  0.000000  0.235702   \n",
      "4    0.000000  0.000000  0.0  0.0  1.0  0.0  0.000000  0.000000  0.000000   \n",
      "..        ...       ...  ...  ...  ...  ...       ...       ...       ...   \n",
      "995  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
      "996  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
      "997  0.377964  0.534522  0.0  0.0  0.0  0.0  0.977356  0.000000  0.000000   \n",
      "998  0.000000  0.000000  0.0  0.0  0.0  0.0  0.000000  0.000000  0.000000   \n",
      "999  0.119523  0.169031  0.0  0.0  0.0  0.0  0.309067  0.105409  0.000000   \n",
      "\n",
      "          9    ...  990  991  992       993  994  995  996       997  998  \\\n",
      "0    0.308607  ...  0.0  0.0  0.0  0.188982  0.0  0.0  0.0  0.377964  0.0   \n",
      "1    0.436436  ...  0.0  0.0  0.0  0.267261  0.0  0.0  0.0  0.534522  0.0   \n",
      "2    0.000000  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0   \n",
      "3    0.000000  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0   \n",
      "4    0.000000  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  0.0   \n",
      "..        ...  ...  ...  ...  ...       ...  ...  ...  ...       ...  ...   \n",
      "995  0.000000  ...  0.0  0.0  0.0  0.000000  0.0  1.0  0.0  0.000000  0.0   \n",
      "996  0.000000  ...  0.0  0.0  0.0  0.000000  0.0  0.0  1.0  0.000000  0.0   \n",
      "997  0.816497  ...  0.0  0.0  0.0  0.500000  0.0  0.0  0.0  1.000000  0.0   \n",
      "998  0.000000  ...  0.0  0.0  0.0  0.000000  0.0  0.0  0.0  0.000000  1.0   \n",
      "999  0.258199  ...  0.0  0.0  0.0  0.158114  0.0  0.0  0.0  0.316228  0.0   \n",
      "\n",
      "          999  \n",
      "0    0.119523  \n",
      "1    0.169031  \n",
      "2    0.000000  \n",
      "3    0.000000  \n",
      "4    0.000000  \n",
      "..        ...  \n",
      "995  0.000000  \n",
      "996  0.000000  \n",
      "997  0.316228  \n",
      "998  0.000000  \n",
      "999  1.000000  \n",
      "\n",
      "[1000 rows x 1000 columns]\n",
      "BOW init\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('ttw2_finalSpell.csv')\n",
    "b1=BOW(df,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 2606)\n"
     ]
    }
   ],
   "source": [
    "temp_df_shape = pd.read_csv('out_work_3.csv')\n",
    "print(temp_df_shape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TFIDF:\n",
    "    #3.3\n",
    "    def __init__(self,df,id_len=1000):\n",
    "        self.df=df\n",
    "        self.id_len=id_len\n",
    "        col=len(self.df.columns)\n",
    "        self.new_df = pd.DataFrame( [[float(0)]*col]*self.id_len )\n",
    "        self.new_df.columns = self.df.columns\n",
    "        \n",
    "        self.wordDict = self.df.columns\n",
    "        \n",
    "        \n",
    "        print(\"shape ---> \",self.new_df.shape)\n",
    "        #print(self.IDF('user'))\n",
    "        #print(\"count --->\",self.calc_tfidf())\n",
    "        self.calc_tfidf()\n",
    "        self.save_csv()\n",
    "        print(\"Init TFIDF Done \")\n",
    "    \n",
    "    #3.2\n",
    "    def calc_tfidf(self):\n",
    "        count=0\n",
    "\n",
    "        #print(len(self.df.columns)*1000)\n",
    "        for word in self.df.columns:\n",
    "            for ID in range(self.id_len):\n",
    "                #temp here\n",
    "                #if word == \"user\":\n",
    "                self.new_df[word][ID]=self.TF(word,ID)*self.IDF(word)\n",
    "                #elif id==5:\n",
    "                    #self.new_df[word][ID]=self.TF(word,ID)*self.IDF(word)\n",
    "    \n",
    "    def TF(self,word,ID):\n",
    "        if self.df[word][ID]>0:\n",
    "            tf=(1+np.log(self.df[word][ID]))\n",
    "            return tf\n",
    "        else:\n",
    "            return 0\n",
    "    def IDF(self,word):\n",
    "        N = self.id_len\n",
    "        #kolichestvo dokymentov soderjashih t\n",
    "        #(self.temp_df[word].loc[self.temp_df[word]==True]).index\n",
    "        #df_t = (self.df[word].loc[self.df[word]]>0).index\n",
    "        \n",
    "        df_t=self.df[word].astype(bool).sum(axis=0)\n",
    "        \n",
    "        #print('df_t  =  ',df_t)\n",
    "        if df_t != 0:\n",
    "            idf = np.log10(N/df_t)\n",
    "            return idf\n",
    "        else:\n",
    "            return df_t\n",
    "    \n",
    "    #3.4\n",
    "    def create_cisine_sim_matrix(self):\n",
    "        self.cisine_sim_matrix=pd.DataFrame( [[float(0)]*self.id_len]*self.id_len )\n",
    "        for X in range(self.id_len):\n",
    "            x = self.new_df.iloc[X].values\n",
    "            for Y in range(X,self.id_len):\n",
    "                y = self.new_df.iloc[Y].values\n",
    "                \n",
    "                #top=self.calc_top(x,y)\n",
    "                #bot=self.calc_gip(x) * self.calc_gip(y) \n",
    "                #self.cisine_sim_matrix[X][Y]=(top/bot)\n",
    "                \n",
    "                self.cisine_sim_matrix[Y][X]=self.cisine_sim_matrix[X][Y]=self.cisine_sim(x,y)       \n",
    "        print(self.cisine_sim_matrix)\n",
    "    \n",
    "    \n",
    "    def calc_top(self,x=None,y=None):\n",
    "        #x = self.df.iloc[0].values\n",
    "        #y = self.df.iloc[0].values\n",
    "        #print(\"x =\",x)\n",
    "        #print(\"y =\",y)\n",
    "        Sum=0\n",
    "        for pointer in range(len(x)):\n",
    "            Sum=Sum+(x[pointer]*y[pointer])\n",
    "        #print(\"Sum  =  \",Sum)\n",
    "        #print(\"bot ->\",self.calc_gip(x) + self.calc_gip(y))\n",
    "        return Sum\n",
    "    \n",
    "    def calc_gip(self,vec):\n",
    "        result=0\n",
    "        for val in vec:\n",
    "            result = result +(val*val)\n",
    "        return math.sqrt(result)\n",
    "    \n",
    "    \n",
    "    def cisine_sim(self,x,y):    \n",
    "        top=self.calc_top(x,y)\n",
    "        bot=self.calc_gip(x) * self.calc_gip(y)\n",
    "        return (top/bot)\n",
    "    \n",
    "    def save_csv(self):\n",
    "        self.new_df.to_csv('out_work_3_TFIDF.csv', index=False)\n",
    "        print(\"save_csv\")\n",
    "\n",
    "        \n",
    "    def create_qws(self,words_list=[]):\n",
    "        self.qws_df = pd.DataFrame( [[int(0)]*len(self.wordDict)]*1 )\n",
    "        print(\"self.qws_df.shape\")\n",
    "        print(self.qws_df.shape)\n",
    "        self.qws_df.columns = self.new_df.columns\n",
    "        print(\"self.qws_df.columns\")\n",
    "        print(self.qws_df.columns)\n",
    "        for word in words_list:\n",
    "            print(\"self.qws_df.columns\")\n",
    "            print(self.qws_df.columns)\n",
    "            if word in self.qws_df.columns:\n",
    "                print(\"self.qws_df[word][0]\")\n",
    "                print(self.qws_df[word][0])\n",
    "                self.qws_df[word][0] = self.qws_df[word][0] + 1\n",
    "                print(\"self.qws_df.iloc[0].values\")\n",
    "                print(self.qws_df.iloc[0].values)\n",
    "        return self.qws_df.iloc[0].values       \n",
    "        \n",
    "        \n",
    "        \n",
    "    def find(self,words_list=[]):\n",
    "        result_arr=[]\n",
    "        \n",
    "        y=self.create_qws(words_list)\n",
    "        for X in range(self.id_len):\n",
    "            print(\"X  -->  \",X-1)\n",
    "            x = self.new_df.iloc[X-1].values\n",
    "            print(\"   x  -->  \",x)\n",
    "            result_arr.append([self.cisine_sim(x,y),X-1])\n",
    "            print(\"result_arr\")\n",
    "            print(result_arr)\n",
    "            \n",
    "            print(\"self.cisine_sim(x,y)\")\n",
    "            print(self.cisine_sim(x,y))\n",
    "        return result_arr.sort(reverse=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape --->  (1000, 2606)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-368-fdc0e866ba14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mbow_df\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'out_work_3.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mi1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTFIDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbow_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-367-7894dc12ba28>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, df, id_len)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;31m#print(self.IDF('user'))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[1;31m#print(\"count --->\",self.calc_tfidf())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_tfidf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Init TFIDF Done \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-367-7894dc12ba28>\u001b[0m in \u001b[0;36mcalc_tfidf\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     27\u001b[0m                 \u001b[1;31m#temp here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m                 \u001b[1;31m#if word == \"user\":\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m                 \u001b[1;31m#elif id==5:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                     \u001b[1;31m#self.new_df[word][ID]=self.TF(word,ID)*self.IDF(word)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1045\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_with_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[1;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[0;32m   3280\u001b[0m                 \u001b[1;31m#  case where it will raise.  (Uh, not clear why)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3281\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3282\u001b[1;33m                     \u001b[0mref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cache_changed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3283\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3284\u001b[0m                     \u001b[1;31m# ref._data.setitem can raise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_maybe_cache_changed\u001b[1;34m(self, item, value)\u001b[0m\n\u001b[0;32m   3239\u001b[0m         \"\"\"The object has called back to us saying maybe it has changed.\n\u001b[0;32m   3240\u001b[0m         \"\"\"\n\u001b[1;32m-> 3241\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3243\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\Users\\user\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset\u001b[1;34m(self, item, value)\u001b[0m\n\u001b[0;32m   1079\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m         \u001b[0mblknos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blknos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m         \u001b[0mblklocs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_blklocs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m         \u001b[0munfit_mgr_locs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bow_df=pd.read_csv('out_work_3.csv')\n",
    "i1=TFIDF(bow_df,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"1\")\n",
    "i1.create_cisine_sim_matrix()\n",
    "#print(i1.cisine_sim(5,\"user\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i1.calc_top()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "## perevernyti tfidf i iskati po slovam\n",
    "## sim bydet iskati po slovam\n",
    "## ispolzovati sim na bow i na TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(i1.find(\"user\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(b1.find(\"user\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TIME\n",
    " long time for creation of create_cisine_sim_matrix(self):\n",
    " and nice time for creation array of doc/N sorted by apearence of \"user\" in doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALSO\n",
    "need to change stract to improve time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
